rm(list=ls())
library(xgboost)
require(MASS)
library(CASdatasets)
require(stats)
library(data.table)
library(plyr)
library(rpart)
library(rpart.plot)
library(pdp)           # for partial dependence plots
library(vip)           # for variable importance plots
library(Hmisc)
library(glmnet)
library(dplyr)
library("wesanderson")
library(statmod)
library(scales)
library(xgboost)
library(locfit)
library(Metrics)
library(ISLR)
library(h2o)
library(tidyr)
library(tibble) 
library(insurancerating)
library(evtree)
library(mgcv)
require(MASS)
library(CASdatasets)
require(stats)
library(data.table)
# library(plyr)
library(dplyr)
library(purrr)
library(rpart)
library(rpart.plot)
library(Hmisc)
library(glmnet)
library(dplyr)
data(freMTPL2freq)
data(freMTPL2sev)
library("wesanderson")
library(statmod)
library(scales)
data(pg17trainpol)
data(pg17trainclaim)
data(pg17testyear1)
data(pg17testyear2)
data(pg17testyear3)
data(pg17testyear4)
data(fredpt17)
library(ggcorrplot)
library(ggplot2)
library(locfit)
library(Metrics)
library(ISLR)
library(h2o)
require(MASS)
library(CASdatasets)
require(stats)
library(data.table)
library(plyr)
library(rpart)
library(rpart.plot)
library(Hmisc)
library(glmnet)
library(dplyr)
data(freMTPL2freq)
data(freMTPL2sev)
library("wesanderson")
library(statmod)
library(scales)
##################################################
clrpal = wes_palette("Zissou1", 22, type = "continuous")
clrpallow = scales::alpha(clrpal,.4)
bleurouge = clrpal[c(1,22)]
bleurougepal = clrpallow[c(1,22)]
colr= clrpal4 = wes_palette("Darjeeling1")[c(1,2,3,5)]
clrpal6 = wes_palette("Zissou1", 6, type = "continuous")
### Initial data call 
#### Aggreagating the two datasets together
freMTPL2sev_tot = aggregate(freMTPL2sev$ClaimAmount,
                            by=list(freMTPL2sev$IDpol),
                            FUN = sum)
names(freMTPL2sev_tot)=names(freMTPL2sev)
freMTPL2 = merge(freMTPL2freq,freMTPL2sev_tot,all.x=TRUE)
freMTPL2$ClaimAmount[is.na(freMTPL2$ClaimAmount)]=0

#### Limiting to only high Exposure policies 
freMTPL2 = freMTPL2[(freMTPL2$Exposure>.8)&(freMTPL2$Exposure<=1),]
##### Removing all large claim values 
freMTPL2 = freMTPL2[freMTPL2$ClaimAmount<=10000,]
dat_freq=freMTPL2  
dat_freq_nonzero = dat_freq[dat_freq$ClaimAmount!=0,]
dat_freq_zero = dat_freq[dat_freq$ClaimAmount==0,]
n_dat_freq_zero=nrow(dat_freq_zero)
set.seed(1001)
keep_in= sample(1:n_dat_freq_zero, size=.4*n_dat_freq_zero, replace=FALSE)
dat_freq_zero_keep= dat_freq_zero[keep_in,]  
dat_freq= rbind(dat_freq_nonzero,dat_freq_zero_keep)  
#########################################################################################  
######## Replacing the FreqMTPL2 label to dat_freq that we commonly use in other code
######## Note dat_freq has both frequemcy and severity data 
freMTPL2_backup = freMTPL2
####### Making adjustments to data 
dat_freq$VehGas <- factor(dat_freq$VehGas)    # consider VehGas as categorical
dat_freq$ClaimNb <- pmin(dat_freq$ClaimNb, 4)   # correct for unreasonable observations (that might be data error)
dat_freq$Exposure <- pmin(dat_freq$Exposure, 1) # correct for unreasonable observations (that might be data error)
dat_freq$Area <- as.factor(dat_freq$Area)   ### Area as factor 
dat_freq$VehPower <- as.factor(pmin(dat_freq$VehPower,9))
dat_freq$BonusMalus <- as.integer(pmin(dat_freq$BonusMalus, 150))
dat_freq$Density <- as.numeric(log(dat_freq$Density))

############## Removing Severity data 
dat_freq_temp= dat_freq[dat_freq$ClaimAmount!=0,]
ID_Exclude1 = dat_freq_temp$IDpol[which(dat_freq_temp$ClaimAmount<100)]
ID_Exclude2 = dat_freq_temp$IDpol[which(dat_freq_temp$ClaimAmount %in% c(1204, 1128.12,1172,1128))]
dat_freq= dat_freq[-which(dat_freq$IDpol %in% c(ID_Exclude1,ID_Exclude2)),]
##### Shuffling the data
n_freq = nrow(dat_freq)
set.seed(100)
reord_freq = sample(1:n_freq, size=n_freq, replace=FALSE)
dat_freq = dat_freq[reord_freq, ] 
dat_freq$ClaimNb=as.numeric(dat_freq$ClaimNb)

features.freq <- setdiff( 1:length(dat_freq) ,  grep("drv_age_lic_avg|id_policy|drv_sex2|vh_make|
      vh_make|drv_age2|drv_age_lic2|vh_din|vh_sale_begin|vh_sale_end|ClaimAmount|drv_age_avg|Exposure|ClaimNb|
      drv_age_lic_avg|vh_cyl", names(dat_freq)))

set.seed(1001)
split1= sample(1:n_freq, size=.833*n_freq, replace=FALSE)
CV_data_freq = dat_freq[split1,]
test_data_freq = dat_freq[-split1,]

dev_poiss <- function(ytrue, ypred, wcase) -2 * weighted.mean(dpois(ytrue, ypred, log = TRUE) - dpois(ytrue, ytrue, log = TRUE), wcase, na.rm = TRUE)
dev_gamma <- function(ytrue, ypred, wcase) -2 * weighted.mean(log(ytrue/ypred) - ((ytrue - ypred) / ypred), wcase, na.rm = TRUE)

##### GBM Model fitting
hyper_grid <- expand.grid(
  n.trees = c(2000),
  shrinkage = c(0.1,0.01,0.001),
  interaction.depth = c(1,2,3)
)
######## The Cross Validation loop goes in here  ####################????????????????????????????
n = nrow(CV_data_freq)
K = 5
folds = cut(1:n, K, labels=FALSE)
err.vinternal.freq=err.vout.freq= numeric(9)
err.cv.in=err.cv.out=matrix("NA",9,5)
pw.opt=cp.opt=err.internal=err.kfold =matrix(NA,5,10) 
p=10
features.xgb.freq <- setdiff( 1:length(CV_data_freq) ,  grep("drv_age_lic_avg|IDpol|drv_sex2|vh_make|
       vh_make|drv_age2|drv_age_lic2|vh_din|vh_sale_begin|vh_sale_end|ClaimAmount|drv_age_avg|Exposure|ClaimNb|
       drv_age_lic_avg|vh_cyl", names(CV_data_freq)))

colnames(CV_data_freq)
set.seed(100)

 for (b in 1:p) {

  ## re shuffling CV data
 n_CV_freq = nrow(CV_data_freq)
 reord_CVfreq = sample(1:n_CV_freq, size=n_CV_freq, replace=FALSE)
 CV_data_freq = CV_data_freq[reord_CVfreq, ]
  
 for(t in 1:K){
 
  ##training sample
    i = which(folds==t)
    vtrain.data.freq=CV_data_freq[-i,]
    valid.data.freq=CV_data_freq[i,]
    
    Ntr = nrow(vtrain.data.freq)
    Ktr = 5
    err.out.freq = numeric(9)
    output.tr=matrix(NA,)
    pw_cv_out=int.output.tr=pred.output.tr=matrix(NA,5,9)

for (c in 1:9) {# tuning tree model (equivalent to cv.glmnet())

   tr.folds = cut(1:Ntr, Ktr, labels=FALSE)
   internal.errors.tr=pdev.errors.tr = numeric(Ktr)
for(k in 1:Ktr){
               ik = which(tr.folds==k)
      vtrain.data.freq.tr = vtrain.data.freq[-ik,]
      valid.data.freq.tr = vtrain.data.freq[ik,]
      ################### Extreme gradient boost matrix

      xgb_vtrain.data.freq.tr <- xgb.DMatrix(data = data.matrix(vtrain.data.freq.tr [,features.xgb.freq]), label = vtrain.data.freq.tr$ClaimNb)
      xgb_valid.data.freq.tr <- xgb.DMatrix(data = data.matrix(valid.data.freq.tr[,features.xgb.freq]), label = valid.data.freq.tr$ClaimNb)

      setinfo(xgb_vtrain.data.freq.tr,"base_margin",log(vtrain.data.freq.tr$Exposure))
      setinfo(xgb_valid.data.freq.tr,"base_margin",log(valid.data.freq.tr$Exposure))

      # train model for the internal loop
      {t1 <- proc.time()
      fit.xgb.freq.tr <- xgb.train(data = xgb_vtrain.data.freq.tr,objective='count:poisson',nrounds = hyper_grid$n.trees[c],
                                   max_depth = hyper_grid$interaction.depth[c],eta = hyper_grid$shrinkage[c],colsample_by_tree = 0.8,subsample = 0.9,min_child_weight = 10,
                                   tree_method = "hist")

      (proc.time()-t1)}

      train_pred<- predict(fit.xgb.freq.tr, newdata= xgb_vtrain.data.freq.tr)
      internal.errors.tr[k] = dev_poiss(vtrain.data.freq.tr$ClaimNb,train_pred,vtrain.data.freq.tr$Exposure )


      valid_pred=predict(fit.xgb.freq.tr, newdata =xgb_valid.data.freq.tr)
      pdev.errors.tr[k] = dev_poiss(valid.data.freq.tr$ClaimNb,valid_pred,valid.data.freq.tr$Exposure)
          }

          int.output.tr[,c]=internal.errors.tr
          pred.output.tr[,c]=pdev.errors.tr

          err.out.freq[c] = mean(pdev.errors.tr) # mean CV error
        }

        cp.opt[t,b] =  which.min(err.out.freq)
      
      # which.min(err.out.freq)
        # pw.opt[t,b]=mean(pw_cv_out[,cp.opt[t]])   #### Using the same power used in the best cp output
    
      #####  The external loop model coded here 

  xgb_vtrain.data.freq <- xgb.DMatrix(data = data.matrix(vtrain.data.freq [,features.xgb.freq]), label = vtrain.data.freq$ClaimNb)
  xgb_valid.data.freq <- xgb.DMatrix(data = data.matrix(valid.data.freq[,features.xgb.freq]), label = valid.data.freq$ClaimNb)
  
  setinfo(xgb_vtrain.data.freq,"base_margin",log(vtrain.data.freq$Exposure))
  setinfo(xgb_valid.data.freq,"base_margin",log(valid.data.freq$Exposure))
  
  # train model
  {t1 <- proc.time()
    xgb_freq_cp_opt<- xgb.train(data = xgb_vtrain.data.freq,objective='count:poisson',nrounds = hyper_grid$n.trees[cp.opt[t,b]],
                                max_depth =hyper_grid$interaction.depth[cp.opt[t,b]] ,eta = hyper_grid$shrinkage[cp.opt[t,b]],colsample_by_tree = 0.8,subsample = 0.9,min_child_weight = 10,
                                tree_method = "hist")
    
      
    (proc.time()-t1)}
  
########################         
    y.internal <- predict(xgb_freq_cp_opt, newdata = xgb_vtrain.data.freq, type="response")
    err.internal[t,b] =dev_poiss(vtrain.data.freq$ClaimNb, y.internal,vtrain.data.freq$Exposure)
    
    y.pred <- predict(xgb_freq_cp_opt, newdata = xgb_valid.data.freq, type="response")
    err.kfold[t,b] =dev_poiss(valid.data.freq$ClaimNb,y.pred,valid.data.freq$Exposure )
    
  }

print(b)
 }

write.csv(err.internal,"err.internal.csv")
write.csv(err.kfold,"err.kfold.csv")

####################### The cross validation loop ends here 
### The most used cp and pw values are used in the final model 
getmode <- function(v) {
  uniqv <- unique(v)
  uniqv[which.max(tabulate(match(v, uniqv)))]
}
train_data=CV_data_freq
test_data=test_data_freq
final.cp.opt= getmode(cp.opt)
#########   Fitting the GLM model to the train data 
xgb_train_data <- xgb.DMatrix(data = data.matrix(train_data [,features.xgb.freq]), label = train_data$ClaimNb)
xgb_test_data <- xgb.DMatrix(data = data.matrix(test_data[,features.xgb.freq]), label = test_data$ClaimNb)

setinfo(xgb_train_data,"base_margin",log(train_data$Exposure))
setinfo(xgb_test_data,"base_margin",log(test_data$Exposure))

# train model

xgb_freq_final<- xgb.train(data = xgb_train_data,objective='count:poisson',nrounds =hyper_grid$n.trees[final.cp.opt],
                               max_depth = hyper_grid$interaction.depth[final.cp.opt],eta = hyper_grid$shrinkage[final.cp.opt],
                               colsample_by_tree = 0.8,subsample = 0.9,min_child_weight = 10, tree_method = "hist")
  
xgb_freq_final$feature_names
var.names=colnames(train_data[features.xgb.freq])
imp_freq_final=xgb.importance(var.names,xgb_freq_final)
write.csv(imp_freq_final,"imp_freq_final_TP.csv")

## frequency testing
Predicted_freq_train <-predict(xgb_freq_final, newdata = xgb_train_data, type="response")
Predicted_freq_train.error =dev_poiss(train_data$ClaimNb,Predicted_freq_train,train_data$Exposure )

Predicted_freq_test<- predict(xgb_freq_final, newdata = xgb_test_data, type="response")
GLM.out.freq.err = dev_poiss(test_data$ClaimNb,Predicted_freq_test,test_data$Exposure )

 final_freq=cbind(Predicted_freq_train.error,GLM.out.freq.err)
 write.csv(final_freq,"final_freq.csv")


##################################################################################
######### Boot 632 for external error on correct data  ######
n_freq_correct=nrow(test_data)
boot632_err_outfreq_correct=err_oob_outfreq_correct=inbag_err_freqout_correct=numeric(250)

 for (t in 1:250) {
  ib = sample(1:n_freq_correct, size=1*n_freq_correct, replace=TRUE)
  inbag_sample_outfreq=test_data[ib,]
  xgb_inbag_sample_outfreq <- xgb.DMatrix(data = data.matrix(inbag_sample_outfreq[,features.xgb.freq]), label = inbag_sample_outfreq$ClaimNb)
  setinfo(xgb_inbag_sample_outfreq,"base_margin",log(inbag_sample_outfreq$Exposure))
  
  pred_inbag_outfreq <- predict(xgb_freq_final, newdata=xgb_inbag_sample_outfreq, type="response")
  inbag_err_freqout_correct[t] =dev_poiss(inbag_sample_outfreq$ClaimNb,pred_inbag_outfreq,inbag_sample_outfreq$Exposure)


  #### oob errror prediction

  oob_outfreq= which(!(test_data$IDpol %in% inbag_sample_outfreq$IDpol))
  oob_sample_outfreq= test_data[oob_outfreq,]
  xgb_oob_sample_outfreq <- xgb.DMatrix(data = data.matrix(oob_sample_outfreq[,features.xgb.freq]), label = oob_sample_outfreq$ClaimNb)
  setinfo(xgb_oob_sample_outfreq,"base_margin",log(oob_sample_outfreq$Exposure))
  
  pred_oob_outfreq <- predict(xgb_freq_final, newdata=xgb_oob_sample_outfreq,type="response")
  
  err_oob_outfreq_correct[t] =dev_poiss(oob_sample_outfreq$ClaimNb,pred_oob_outfreq,oob_sample_outfreq$Exposure)

  boot632_err_outfreq_correct[t] = 0.368 * err_oob_outfreq_correct[t] + 0.632 * inbag_err_freqout_correct[t]

}

bootstrap_freqout_correct=cbind(boot632_err_outfreq_correct,err_oob_outfreq_correct,inbag_err_freqout_correct)
write.csv(bootstrap_freqout_correct,"bootstrap_freqout_correct.csv")

##########~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
####################### Severity Model, the data setup starts here 3########

dat_severity=dat_freq[dat_freq$ClaimAmount!=0,]
n_severity = nrow(dat_severity)
set.seed(1001)
reord_sev = sample(1:n_severity, size=n_severity, replace=FALSE)
dat_severity = dat_severity[reord_sev, ] 
dat_severity$AverageClaim=dat_severity$ClaimAmount/dat_severity$ClaimNb
# save a validation sample for later:
set.seed(100)
i.valid_sev = sample(1:n_severity, size=.833*n_severity, replace=FALSE)
CV_data_sev = dat_severity[i.valid_sev,]
test_data_sev = dat_severity[-i.valid_sev,]
train_data_nonzero= CV_data_sev
test_data_nonzero= test_data_sev

################################################
######## The Cross Validation loop goes in here  ####################????????????????????????????
n = nrow(train_data_nonzero)
K = 5
folds = cut(1:n, K, labels=FALSE)
err.vinternal.sev=err.vout.sev= numeric(9)
err.cv.in.sev=err.cv.out.sev=matrix("NA",9,5)
pw.opt.sev=cp.opt.sev=err.internal.sev=err.kfold.sev =matrix(NA,5,10) 
features.xgb.sev <- setdiff( 1:length(train_data_nonzero) ,  grep("AverageClaim|id_policy|drv_sex2|IDpol|
 vh_make|vh_make|drv_age2|drv_age_lic2|vh_din|vh_sale_begin|vh_sale_end|ClaimAmount|drv_age_avg|Exposure|ClaimNb|drv_age_lic_avg|id_policy|vh_cyl", names(train_data_nonzero)  ))
colnames(train_data_nonzero)
p=10
set.seed(100)
 
 for (b in 1:p) {

  # ## re shufling CV data
n_CV_sev = nrow(train_data_nonzero)
reord_CVsev = sample(1:n_CV_sev, size=n_CV_sev, replace=FALSE)
CV_data_sev = train_data_nonzero[reord_CVsev, ]

 for(t in 1:K){
  ##training sample
i = which(folds==t)
vtrain.data.sev=CV_data_sev[-i,]
valid.data.sev=CV_data_sev[i,]

Ntr = nrow(vtrain.data.sev)
Ktr = 5
err.out.sev = numeric(9)
pw_cv_out.sev=int.output.tr.sev=pred.output.tr.sev=matrix(NA,5,9)

for (c in 1:9) {

 # tuning tree model (equivalent to cv.glmnet())
tr.folds = cut(1:Ntr, Ktr, labels=FALSE)
internal.errors.tr.sev=pdev.errors.tr.sev = numeric(Ktr)

for(k in 1:Ktr){
ik = which(tr.folds==k)
vtrain.data.sev.tr = vtrain.data.sev[-ik,]
valid.data.sev.tr = vtrain.data.sev[ik,]
################### Extremme gradient boost matrix

xgb_vtrain.data.sev.tr <- xgb.DMatrix(data = data.matrix(vtrain.data.sev.tr [,features.xgb.sev]), label = vtrain.data.sev.tr$AverageClaim)
xgb_valid.data.sev.tr <- xgb.DMatrix(data = data.matrix(valid.data.sev.tr[,features.xgb.sev]), label = valid.data.sev.tr$AverageClaim)

####################################  testing for the correct power
# train model for the internal loop
{t1 <- proc.time()
fit.xgb.sev.tr <- xgb.train(data = xgb_vtrain.data.sev.tr,objective='reg:gamma',nrounds = hyper_grid$n.trees[c],
                             max_depth = hyper_grid$interaction.depth[c],eta = hyper_grid$shrinkage[c],colsample_by_tree = 0.8,subsample = 0.9,min_child_weight = 10,
                            weight=vtrain.data.sev.tr$ClaimNb)


(proc.time()-t1)}

train_pred_sev<- predict(fit.xgb.sev.tr, newdata= xgb_vtrain.data.sev.tr)
internal.errors.tr.sev[k] = dev_gamma(vtrain.data.sev.tr$AverageClaim,train_pred_sev, vtrain.data.sev.tr$ClaimNb)

valid_pred_sev=predict(fit.xgb.sev.tr, newdata =xgb_valid.data.sev.tr)
pdev.errors.tr.sev[k] = dev_gamma(valid.data.sev.tr$AverageClaim,valid_pred_sev, valid.data.sev.tr$ClaimNb)

 }
### Writing out the internal loop results

int.output.tr.sev[,c]=internal.errors.tr.sev
pred.output.tr.sev[,c]=pdev.errors.tr.sev

err.out.sev[c] = mean(pdev.errors.tr.sev) # mean CV error
}

err.cv.out.sev[,t]=err.out.sev
cp.opt.sev[t,b] = which.min(err.out.sev)

#####  The external loop model coded here 
xgb_vtrain.data.sev <- xgb.DMatrix(data = data.matrix(vtrain.data.sev [,features.xgb.sev]), label = vtrain.data.sev$AverageClaim)
xgb_valid.data.sev <- xgb.DMatrix(data = data.matrix(valid.data.sev[,features.xgb.sev]), label = valid.data.sev$AverageClaim)

# train model
{t1 <- proc.time()
  xgb_sev_cp_opt<- xgb.train(data = xgb_vtrain.data.sev,objective='reg:gamma',nrounds = hyper_grid$n.trees[cp.opt.sev[t,b]],
                              max_depth =hyper_grid$interaction.depth[cp.opt.sev[t,b]] ,eta = hyper_grid$shrinkage[cp.opt.sev[t,b]],colsample_by_tree = 0.8,subsample = 0.9,min_child_weight = 10,
                             weight=vtrain.data.sev$ClaimNb)
  
  
  (proc.time()-t1)}

########################         
y.internal.sev <- predict(xgb_sev_cp_opt, newdata = xgb_vtrain.data.sev, type="response")
err.internal.sev[t,b] =dev_gamma(vtrain.data.sev$AverageClaim, y.internal.sev,vtrain.data.sev$ClaimNb)

y.pred.sev <- predict(xgb_sev_cp_opt, newdata = xgb_valid.data.sev, type="response")
err.kfold.sev[t,b] =dev_gamma(valid.data.sev$AverageClaim,y.pred.sev,valid.data.sev$ClaimNb )

}
 print(b)
}

write.csv(err.internal.sev,"err.internal.sev.csv")
write.csv(err.kfold.sev,"err.kfold.sev.csv")
####################### The cross validation loop ends here 
getmode <- function(v) {
  uniqv <- unique(v)
  uniqv[which.max(tabulate(match(v, uniqv)))]
}
hyper_grid
final.cp.opt.sev= getmode(cp.opt.sev) 
#########   Fitting the GLM model to the train data 
xgb_train_data_sev <- xgb.DMatrix(data = data.matrix(train_data_nonzero [,features.xgb.sev]), label = train_data_nonzero$AverageClaim)
xgb_test_data_sev <- xgb.DMatrix(data = data.matrix(test_data_nonzero[,features.xgb.sev]), label = test_data_nonzero$AverageClaim)

# train model

xgb_sev_final<- xgb.train(data = xgb_train_data_sev,objective='reg:gamma',nrounds =hyper_grid$n.trees[final.cp.opt.sev],
                           max_depth = hyper_grid$interaction.depth[final.cp.opt.sev],eta = hyper_grid$shrinkage[final.cp.opt.sev], weight=train_data_nonzero$ClaimNb)


xgb_sev_final$feature_names
var.names=colnames(train_data[features.xgb.sev])
imp_sev_final=xgb.importance(var.names,xgb_sev_final)
write.csv(imp_sev_final,"imp_sev_final_TP.csv")

## frequency testing
Predicted_sev_train <-predict(xgb_sev_final, newdata = xgb_train_data_sev, type="response")
Predicted_sev_train.error =dev_gamma(train_data_nonzero$AverageClaim,Predicted_sev_train,train_data_nonzero$ClaimNb)

Predicted_sev_test<- predict(xgb_sev_final, newdata = xgb_test_data_sev, type="response")
GLM.out.sev.err = dev_gamma(test_data_nonzero$AverageClaim,Predicted_sev_test,test_data_nonzero$ClaimNb)

final_sev=cbind(Predicted_sev_train.error,GLM.out.sev.err)
write.csv(final_sev,"final_sev.csv")
###########################################################################
## Boot 632 of the external error

n_sev=nrow(test_data_nonzero)
boot632_err_outsev=err_oob_outsev=inbag_err_sevout=numeric(250)

for (t in 1:250) {

  ib_sev = sample(1:n_sev, size=1*n_sev, replace=TRUE)
  inbag_sample_outsev=test_data_nonzero[ib_sev,]
  
  xgb_inbag_sample_outsev <- xgb.DMatrix(data = data.matrix(inbag_sample_outsev [,features.xgb.sev]), label = inbag_sample_outsev$AverageClaim)
  
  pred_inbag_outsev <- predict(xgb_sev_final, newdata=xgb_inbag_sample_outsev,type="response")
  inbag_err_sevout[t] =dev_gamma(inbag_sample_outsev$AverageClaim,pred_inbag_outsev,inbag_sample_outsev$ClaimNb)
  
  #### oob errror prediction
  
  oob_outsev= which(!(test_data_nonzero$IDpol %in% inbag_sample_outsev$IDpol))     
  oob_sample_outsev= test_data_nonzero[oob_outsev,]
  
  xgb_oob_sample_outsev <- xgb.DMatrix(data = data.matrix(oob_sample_outsev [,features.xgb.sev]), label = oob_sample_outsev$AverageClaim)
  
  pred_oob_outsev <- predict(xgb_sev_final, newdata=xgb_oob_sample_outsev,type="response")
  err_oob_outsev[t] = dev_gamma(oob_sample_outsev$AverageClaim,pred_oob_outsev,oob_sample_outsev$ClaimNb)
  
  boot632_err_outsev [t] = 0.368 * err_oob_outsev[t] + 0.632 * inbag_err_sevout[t]
  
}
bootstrap_sevout=cbind(boot632_err_outsev,err_oob_outsev,inbag_err_sevout)
write.csv(bootstrap_sevout,"bootstrap_sevout.csv")
range_sevout= cbind(quantile(boot632_err_outsev,0.025),quantile(boot632_err_outsev,0.975))
boxplot(inbag_err_sevout)
###################### Overall Premium will start here 
####### Taking the original Frequency test data to get the final prediction of premium#################
test_data
Predicted_freq_test ### Predicted claims frequecny 

#### Without base margin data created for severity 
xgb_test_data_freq_sev=xgb.DMatrix(data = data.matrix(test_data [,features.xgb.sev]), label = test_data$ClaimNb)
Pred_severity <- predict(xgb_sev_final, newdata=xgb_test_data_freq_sev,type="response") #### Predicted Severity Final 
orignal_data= test_data$ClaimAmount

predicted_premium= Predicted_freq_test*Pred_severity*test_data$Exposure
a1= sum(predicted_premium)
a2=sum(orignal_data)
a1-a2
error_prem= (a2-a1)/a1 

write.csv(predicted_premium,"predicted_prem_xgb.csv")
write.csv(test_data_freq, "test_data_xgb.csv")
write.csv(orignal_data,"orignal_data_xgb.csv")

####### Bootstrap 632 for bias ##########################################################
n = nrow(test_data)
B = 250
pred_inbag=Actual_inbag=bias_inbag=percent.bias_inbag=pred_oob= Actual_oob= bias_oob= percent.bias_oob=boot632_bias= boot632_bias_perc=numeric(B)

for(b in 1:B){
  ib_bias = sample(1:n, size=1*n, replace=TRUE)
  
  ####### in sample bias calculation
  inbag_sample_bias=test_data[ib_bias,]
  xgb_inbag_sample_sev_bias <- xgb.DMatrix(data = data.matrix(inbag_sample_bias [,features.xgb.sev]), label = inbag_sample_bias$ClaimNb)
  
  xgb_inbag_sample_freq_bias <- xgb.DMatrix(data = data.matrix(inbag_sample_bias [,features.xgb.freq]), label = inbag_sample_bias$ClaimNb)
  setinfo(xgb_inbag_sample_freq_bias,"base_margin",log(inbag_sample_bias$Exposure))
  
  #### Freq for bias################################################################
  
  pred_freq_inbag <- predict(xgb_freq_final, newdata=xgb_inbag_sample_freq_bias,type="response")
  ### Sevrity part of the bias
  Pred_severity_inbag <- predict(xgb_sev_final, newdata=xgb_inbag_sample_sev_bias,type="response") #### Predicted Severity Final
  ### comparison step
  orignal_data_inbag= inbag_sample_bias$ClaimAmount
  
  predicted_premium_inbag= pred_freq_inbag*Pred_severity_inbag*inbag_sample_bias$Exposure
  
  pred_inbag[b]=sum(predicted_premium_inbag)
  Actual_inbag[b]= sum(orignal_data_inbag)
  
  bias_inbag[b] = Actual_inbag[b]-pred_inbag[b]
  percent.bias_inbag[b]=bias_inbag[b]/ Actual_inbag[b]
  
  ##### Out of bag bias evaluation ############################################ 
  
  oob_sample= which(!(test_data$IDpol %in% inbag_sample_bias$IDpol))
  oob_sample_bias= test_data[oob_sample,]
  
  #### Freq for bias###################################
  
  xgb_oob_sample_sev_bias <- xgb.DMatrix(data = data.matrix(oob_sample_bias [,features.xgb.sev]), label = oob_sample_bias$ClaimNb)
  xgb_oob_sample_freq_bias <- xgb.DMatrix(data = data.matrix(oob_sample_bias [,features.xgb.freq]), label = oob_sample_bias$ClaimNb)
  setinfo(xgb_oob_sample_freq_bias,"base_margin",log(oob_sample_bias$Exposure))
  
  
  pred_freq_oob <- predict(xgb_freq_final, newdata=xgb_oob_sample_freq_bias,type="response")
  ### Sevrity part of the bias
  Pred_severity_oob <- predict(xgb_sev_final, newdata=xgb_oob_sample_sev_bias,type="response") #### Predicted Severity Final
  ### comparison step
  orignal_data_oob= oob_sample_bias$ClaimAmount
  
  predicted_premium_oob= pred_freq_oob*Pred_severity_oob*oob_sample_bias$Exposure
  
  pred_oob[b]=sum(predicted_premium_oob)
  Actual_oob[b]= sum(orignal_data_oob)
  
  bias_oob[b] = Actual_oob[b]-pred_oob[b]
  percent.bias_oob[b]=bias_oob[b]/ Actual_oob[b]
  
  ########### Final 632 errors to be used #####################################
  
  boot632_bias[b] = 0.368 * bias_oob[b] + 0.632 * bias_inbag[b]
  
  boot632_bias_perc[b] = 0.368 * percent.bias_oob[b] + 0.632 * percent.bias_inbag[b]
  
}
bootstrap_bias=cbind(bias_inbag,percent.bias_inbag,bias_oob,percent.bias_oob,boot632_bias, boot632_bias_perc)
write.csv(bootstrap_bias,"bootstrap_bias.csv")

mean(boot632_bias_perc)



